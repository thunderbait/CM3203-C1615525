{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#from custom_functions import process_dfs, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dfs(train_df, test_df):\n",
    "    print(\"Processing dfs...\")\n",
    "    print(\"Dropping repeated columns...\")\n",
    "    columns = [col for col in train_df.columns if train_df[col].nunique() > 1]\n",
    "\n",
    "    train_df = train_df[columns]\n",
    "    test_df = test_df[columns]\n",
    "\n",
    "    trn_len = train_df.shape[0]\n",
    "\n",
    "    merged_df = pd.concat([train_df, test_df])\n",
    "\n",
    "    merged_df['diff_visitId_time'] = merged_df['visitId'] - merged_df['visitStartTime']\n",
    "    merged_df['diff_visitId_time'] = (merged_df['diff_visitId_time'] != 0).astype(int)\n",
    "    del merged_df['visitId']\n",
    "\n",
    "    print(\"Generating date columns...\")\n",
    "    format_str = '%Y%m%d'\n",
    "    merged_df['formated_date'] = merged_df['date'].apply(lambda x: datetime.strptime(str(x), format_str))\n",
    "    merged_df['WoY'] = merged_df['formated_date'].apply(lambda x: x.isocalendar()[1])\n",
    "    merged_df['month'] = merged_df['formated_date'].apply(lambda x:x.month)\n",
    "    merged_df['quarter_month'] = merged_df['formated_date'].apply(lambda x:x.day//8)\n",
    "    merged_df['weekday'] = merged_df['formated_date'].apply(lambda x:x.weekday())\n",
    "\n",
    "    del merged_df['date']\n",
    "    del merged_df['formated_date']\n",
    "\n",
    "    merged_df['formated_visitStartTime'] = merged_df['visitStartTime'].apply(lambda x: time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(x)))\n",
    "    merged_df['formated_visitStartTime'] = pd.to_datetime(merged_df['formated_visitStartTime'])\n",
    "    merged_df['visit_hour'] = merged_df['formated_visitStartTime'].apply(lambda x: x.hour)\n",
    "\n",
    "    del merged_df['visitStartTime']\n",
    "    del merged_df['formated_visitStartTime']\n",
    "\n",
    "    print(\"Encoding columns with pd.factorize()\")\n",
    "    for col in merged_df.columns:\n",
    "        if col in ['fullVisitorId', 'month', 'quarter_month', 'weekday', 'visit_hour', 'WoY']: continue\n",
    "        if merged_df[col].dtypes == object or merged_df[col].dtypes == bool: merged_df[col], indexer = pd.factorize(merged_df[col])\n",
    "\n",
    "    print(\"Splitting back...\")\n",
    "    train_df = merged_df[:trn_len]\n",
    "    test_df = merged_df[trn_len:]\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    train_df = pd.read_csv('train-flattened.csv', dtype = {'fullVisitorId' : np.str})\n",
    "    test_df = pd.read_csv('test-flattened.csv', dtype = {'fullVisitorId' : np.str})\n",
    "\n",
    "    target = train_df['totals.transactionRevenue'].fillna(0).astype(float)\n",
    "    target = target.apply(lambda x: np.log1p(x))\n",
    "\n",
    "    del train_df['totals.transactionRevenue']\n",
    "\n",
    "    train_df, test_df = process_dfs(train_df, test_df)\n",
    "    train_df.to_csv('train-flat-clean.csv', index=False)\n",
    "    test_df.to_csv('test-flat-clean.csv', index=False)\n",
    "    target.to_csv('target.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dfs...\n",
      "Dropping repeated columns...\n",
      "Generating date columns...\n",
      "Encoding columns with pd.factorize()\n",
      "Splitting back...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return round(np.sqrt(mean_squared_error(y_true, y_pred)), 5)\n",
    "\n",
    "def load_preprocessed_dfs(drop_full_visitor_id=True):\n",
    "\n",
    "    X_train = pd.read_csv('train-flat-clean.csv', converters={'fullVisitorId': str})\n",
    "    X_test = pd.read_csv('test-flat-clean.csv', converters={'fullVisitorId': str})\n",
    "    y_train = pd.read_csv('target.csv', names=['LogRevenue']).T.squeeze()\n",
    "    \n",
    "    # This is the only `object` column, we drop it for train and evaluation\n",
    "    if drop_full_visitor_id: \n",
    "        X_train = X_train.drop(['fullVisitorId'], axis=1)\n",
    "        X_test = X_test.drop(['fullVisitorId'], axis=1)\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1452086, 28)\n",
      "Validation shape: (256251, 28)\n",
      "Test (submit) shape: (401589, 28)\n"
     ]
    }
   ],
   "source": [
    "X, y, X_test = load_preprocessed_dfs()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=1)\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}\")\n",
    "print(f\"Validation shape: {X_val.shape}\")\n",
    "print(f\"Test (submit) shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgb(X_train, y_train, X_val, y_val, X_test):\n",
    "    \n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 40,\n",
    "        \"learning_rate\" : 0.005,\n",
    "        \"bagging_fraction\" : 0.6,\n",
    "        \"feature_fraction\" : 0.6,\n",
    "        \"bagging_frequency\" : 6,\n",
    "        \"bagging_seed\" : 42,\n",
    "        \"verbosity\" : -1,\n",
    "        \"seed\": 42\n",
    "    }\n",
    "    \n",
    "    lgb_train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    lgb_val_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "    model = lgb.train(params, lgb_train_data, \n",
    "                      num_boost_round=5000,\n",
    "                      valid_sets=[lgb_train_data, lgb_val_data],\n",
    "                      early_stopping_rounds=100,\n",
    "                      verbose_eval=500)\n",
    "\n",
    "    y_pred_train = model.predict(X_train, num_iteration=model.best_iteration)\n",
    "    y_pred_val = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    y_pred_submit = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "    print(f\"LGBM: RMSE val: {rmse(y_val, y_pred_val)}  - RMSE train: {rmse(y_train, y_pred_train)}\")\n",
    "    return y_pred_submit, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\ttraining's rmse: 1.54423\tvalid_1's rmse: 1.54925\n",
      "[1000]\ttraining's rmse: 1.51136\tvalid_1's rmse: 1.52649\n",
      "[1500]\ttraining's rmse: 1.49538\tvalid_1's rmse: 1.51993\n",
      "[2000]\ttraining's rmse: 1.48426\tvalid_1's rmse: 1.51742\n",
      "[2500]\ttraining's rmse: 1.47444\tvalid_1's rmse: 1.51563\n",
      "[3000]\ttraining's rmse: 1.46374\tvalid_1's rmse: 1.51284\n",
      "[3500]\ttraining's rmse: 1.45537\tvalid_1's rmse: 1.51164\n",
      "[4000]\ttraining's rmse: 1.44742\tvalid_1's rmse: 1.51102\n",
      "[4500]\ttraining's rmse: 1.44024\tvalid_1's rmse: 1.51045\n",
      "Early stopping, best iteration is:\n",
      "[4541]\ttraining's rmse: 1.43978\tvalid_1's rmse: 1.51041\n",
      "LGBM: RMSE val: 1.51041  - RMSE train: 1.43978\n",
      "Wall time: 16min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train LGBM and generate predictions\n",
    "lgb_preds, lgb_model = run_lgb(X_train, y_train, X_val, y_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM features importance...\n",
      "                       feature  split       gain\n",
      "14            totals.pageviews  21137  36.398628\n",
      "13                 totals.hits  22087  16.113187\n",
      "8           geoNetwork.country   5494   8.035801\n",
      "1                  visitNumber  13343   7.912991\n",
      "12     geoNetwork.subContinent   2227   3.410221\n",
      "23                         WoY  17384   3.330303\n",
      "19  trafficSource.referralPath   4711   2.745126\n",
      "9             geoNetwork.metro   8117   2.621198\n",
      "27                  visit_hour  12882   2.233870\n",
      "6              geoNetwork.city  10016   1.758559\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM features importance...\")\n",
    "gain = lgb_model.feature_importance('gain')\n",
    "featureimp = pd.DataFrame({'feature': lgb_model.feature_name(), \n",
    "                   'split': lgb_model.feature_importance('split'), \n",
    "                   'gain': 100 * gain / gain.sum()}).sort_values('gain', ascending=False)\n",
    "print(featureimp[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
